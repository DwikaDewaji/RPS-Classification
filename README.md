# Rock Paper Scissors Image Classification
Predict whether an image is scissors, rock, or paper

## List of contents
- [Introduction](#introduction)
- [Features](#features)
- [Usability](#usability)
- [Project Structure](#project-structure)
- [Contribution](#contribution)
- [License](#license)

## Introduction
This project focuses on creating a machine learning model to classify images of hand gestures representing rock, paper, and scissors. Using advanced deep learning techniques and a diverse dataset, the model aims to accurately identify each gesture, enabling applications in gaming, human-computer interaction, and more. The project includes data collection, preprocessing, model training, and evaluation to ensure high performance and reliability.

## Features
- **Collecting Data**: Collect data from github.
- **Pre-Processing Data**: Resizinh data for accurate analysis.
- **Image Classification**: Using NN models to classify images.



## Usability
1. Run a RPS_Classification script to classify images:
    ```sh
    python RPS_Classification.ipynb
    ```


## Project Structure
- `RPS_Classification.ipynb`: Preprocessing and predicting output. 
- `requirements.txt`: List of required dependencies.

## Contribution
Contributions are very welcome! Please fork this repository and create a pull request with your proposed changes.

## License
This project is licensed under the MIT License. See the `LICENSE` file for more information.
